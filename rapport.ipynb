{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tree leaf recognition\n",
    "## Explication du code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Librairies et Varaibles Globals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1 Librairies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import caer\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import makegraph\n",
    "import makepreproccesing\n",
    "from prettytable import PrettyTable\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from math import sqrt, floor\n",
    "from matplotlib import colors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 Variable Globals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "char_path_train = './Datasets/train'  # chemin vers le dossier train\n",
    "char_path_validation = './Datasets/validation'  # chemin vers le dossier validation\n",
    "char_path_test = './Datasets/test'  # chemin vers le dossier test\n",
    "model_version = 25  # la version du modèle\n",
    "modelse = 'model_' + str(model_version)  # nom complet du model\n",
    "\n",
    "IMG_SIZE = (64, 64)  # resize des images\n",
    "channels = 1\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "dict = {}\n",
    "leaf = []  # tableau comportant les feuilles de train et validation\n",
    "sample_count = []  # tableau comportant le nombre de feuilles par famille de train et validation\n",
    "sample_name = []  # tableau comportant les noms des feuilles de train et validation\n",
    "class_weight = {}  # dictionnaire comportant les poids des feuilles de train et validation\n",
    "label_map = {}  # dictionnaire comportant les index et nom des feuilles de train et validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A partir du fichier train on crée un fichier validation et en split en deux parties les photos qui se trouvaient dans train :\n",
    "- 80% dans le fichier train\n",
    "- 20% dans le fichier validation\n",
    "Rem : aucune photo se trouvant dans train est identique a au phto dans validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_validation(validation_split):\n",
    "    \"\"\"\n",
    "    cette fonction créer un dossier avec 20% des feuilles qui se trouve dans le dossier TRAIN\n",
    "    :param validation_split:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if os.path.isdir(char_path_validation):\n",
    "        print('Validation directory already created!')\n",
    "        print('Process Terminated')\n",
    "        return\n",
    "    os.mkdir(char_path_validation)\n",
    "    for f in os.listdir(char_path_train):\n",
    "        train_class_path = os.path.join(char_path_train, f)\n",
    "        if os.path.isdir(train_class_path):\n",
    "            validation_class_path = os.path.join(char_path_validation, f)\n",
    "            os.mkdir(validation_class_path)\n",
    "            files_to_move = int(validation_split * len(os.listdir(train_class_path)))\n",
    "\n",
    "            for i in range(files_to_move):\n",
    "                random_image = os.path.join(train_class_path, random.choice(os.listdir(train_class_path)))\n",
    "                shutil.move(random_image, validation_class_path)\n",
    "    print('le folder de validation représente {:.2%} du folder train'.format(validation_split))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creation de 3 tableau (leaf, sample_count, sample_name):\n",
    "- on prend seulement 10 species avec le plus grand nombre de photo\n",
    "- on tri les 3 tableaux\n",
    "leaf : [[train][validation]]\n",
    "[['maclura_pomifera', 'ulmus_rubra', 'prunus_virginiana', 'acer_rubrum', 'broussonettia_papyrifera', 'prunus_sargentii', 'ptelea_trifoliata', 'ulmus_pumila', 'abies_concolor', 'asimina_triloba'], ['maclura_pomifera', 'ulmus_rubra', 'prunus_virginiana', 'acer_rubrum', 'broussonettia_papyrifera', 'prunus_sargentii', 'ptelea_trifoliata', 'ulmus_pumila', 'abies_concolor', 'asimina_triloba']]\n",
    "sample name:\n",
    "[['maclura_pomifera', 'ulmus_rubra', 'prunus_virginiana', 'acer_rubrum', 'broussonettia_papyrifera', 'prunus_sargentii', 'ptelea_trifoliata', 'ulmus_pumila', 'abies_concolor', 'asimina_triloba'], ['maclura_pomifera', 'ulmus_rubra', 'prunus_virginiana', 'acer_rubrum', 'broussonettia_papyrifera', 'prunus_sargentii', 'ptelea_trifoliata', 'ulmus_pumila', 'abies_concolor', 'asimina_triloba']]\n",
    "sample count\n",
    "[[286, 203, 193, 190, 187, 183, 172, 169, 160, 159], [71, 50, 48, 47, 47, 46, 43, 42, 40, 39]]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_list(path, x):\n",
    "    \"\"\"\n",
    "    cette fonction remplie 3 tableau (leaf, sample_count, sample_name) qui vont facilité l'accès au image et à leur tri\n",
    "    :param path:\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dicts = {}\n",
    "    for char in os.listdir(path):\n",
    "        dicts[char] = len(os.listdir(os.path.join(path, char)))\n",
    "    dicts = caer.sort_dict(dicts, descending=True)\n",
    "    dict[x] = dicts\n",
    "    count = 0\n",
    "    tableau = []\n",
    "    tableau1 = []\n",
    "    tableau2 = []\n",
    "    for i in dict[x]:\n",
    "        tableau.append(i[0])\n",
    "        tableau1.append(i[1])\n",
    "        tableau2.append(i[0])\n",
    "        count += 1\n",
    "        if count >= 10:\n",
    "            break\n",
    "\n",
    "    leaf.append(tableau)\n",
    "    sample_count.append(tableau1)\n",
    "    sample_name.append(tableau2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "On demande a utilisateur si il veut utilisé la méthode avec le background\n",
    "ON verifie si un modele est deja charger si oui on lance la prediction\n",
    "sinon on train un nouveau modele"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "if input(\"Voulez vous utilisé la méthode avec background (pas optimisé) y ou n : \") == 'y':\n",
    "    background = True\n",
    "# Création du model\n",
    "model = create_model()\n",
    "if background:\n",
    "    if os.path.exists('model/background/' + str(modelse) + '.h5'):\n",
    "        model.load_weights('model/background/' + str(modelse) + '.h5')\n",
    "        train(model, True, background)\n",
    "    else:\n",
    "        train(model, False, background)\n",
    "else:\n",
    "    if os.path.exists('model/normal/' + str(modelse) + '.h5'):\n",
    "        model.load_weights('model/normal/' + str(modelse) + '.h5')\n",
    "        train(model, True, background)\n",
    "    else:\n",
    "        train(model, False, background)\n",
    "\n",
    "if background:\n",
    "    test_datagen = image.ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        preprocessing_function=makepreproccesing.color_segment_function,\n",
    "        fill_mode='nearest')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "on prepare nos photo a effectuer le test en les resisant ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        char_path_test,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=1,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "on affiche le resultat dans un tableau dans le terminal\n",
    "on effectuer la prediction par rapport au photo qui se trouve dnas le dossier test (rem: auncune phto se trouve dans le dossier train ou validation)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('---- Résultat de la prédiction -----')\n",
    "result = model.predict(test_generator, steps=test_generator.n, verbose=1)\n",
    "predicted_class_indices = np.argmax(result, axis=1)\n",
    "prediction_labels = [label_map[k] for k in predicted_class_indices]\n",
    "filenames = test_generator.filenames\n",
    "headers = ['file', 'species']\n",
    "t = PrettyTable(headers)\n",
    "for i, f, p in zip(range(len(filenames)), filenames, prediction_labels):\n",
    "    if i < 10:\n",
    "        t.add_row([os.path.basename(f), p])\n",
    "    elif i < 13:\n",
    "        t.add_row(['.', '.'])\n",
    "print(t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "creation des dossier utile"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "background = False\n",
    "    if not os.path.exists('./model'):\n",
    "        os.mkdir('./model')\n",
    "    if not os.path.exists('./model/background'):\n",
    "        os.mkdir('./model/background')\n",
    "    if not os.path.exists('./model/normal'):\n",
    "        os.mkdir('./model/normal')\n",
    "    if not os.path.exists('./graph/' + str(modelse)):\n",
    "        os.mkdir('./graph/' + str(modelse))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"\n",
    "    cette fonction défini le model que nous allons utilisé (2 layers)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    cnn = tf.keras.models.Sequential()\n",
    "\n",
    "    cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "    cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "    cnn.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "    cnn.add(tf.keras.layers.Dense(units=len(leaf[0]), activation='softmax'))\n",
    "    cnn.summary()\n",
    "\n",
    "    return cnn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def weigth(training_set):\n",
    "    \"\"\"\n",
    "    Fonction qui calcule le poid de chacune des classes\n",
    "    :param training_set:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for k, v in training_set.class_indices.items():\n",
    "        label_map[v] = k\n",
    "\n",
    "    class_counts = pd.Series(training_set.classes).value_counts()\n",
    "\n",
    "    for i, c in class_counts.items():\n",
    "        class_weight[i] = 1.0 / c\n",
    "\n",
    "    norm_factor = np.mean(list(class_weight.values()))\n",
    "\n",
    "    for k in class_counts.keys():\n",
    "        class_weight[k] = class_weight[k] / norm_factor\n",
    "\n",
    "    t = PrettyTable(['class_index', 'class_label', 'class_weight'])\n",
    "    for i in sorted(class_weight.keys()):\n",
    "        t.add_row([i, label_map[i], '{:.2f}'.format(class_weight[i])])\n",
    "    print(t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(model, x, background):\n",
    "    \"\"\"\n",
    "    Fonction a définir TODO\n",
    "    :param model:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if background:\n",
    "        train_datagen = image.ImageDataGenerator(\n",
    "            rescale=1. / 255,\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.0,\n",
    "            height_shift_range=0.0,\n",
    "            shear_range=0.0,\n",
    "            zoom_range=0.0,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            preprocessing_function=makepreproccesing.color_segment_function,\n",
    "            fill_mode='nearest')\n",
    "        test_datagen = image.ImageDataGenerator(\n",
    "            rescale=1. / 255,\n",
    "            preprocessing_function=makepreproccesing.color_segment_function,\n",
    "            fill_mode='nearest')\n",
    "    else:\n",
    "        train_datagen = image.ImageDataGenerator(\n",
    "            rescale=1. / 255,\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.0,\n",
    "            height_shift_range=0.0,\n",
    "            shear_range=0.0,\n",
    "            zoom_range=0.0,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            fill_mode='nearest')\n",
    "        test_datagen = image.ImageDataGenerator(\n",
    "            rescale=1. / 255,\n",
    "            fill_mode='nearest')\n",
    "\n",
    "    training_set = train_datagen.flow_from_directory(\n",
    "        char_path_train,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        classes=leaf[0])\n",
    "    test_set = test_datagen.flow_from_directory(\n",
    "        char_path_validation,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical', classes=leaf[0])\n",
    "\n",
    "    weigth(training_set)\n",
    "    if not x:\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        History = model.fit(training_set, validation_data=test_set, epochs=EPOCHS, class_weight=class_weight)\n",
    "\n",
    "        makegraph.make_graph_accuracy(History, modelse)\n",
    "        makegraph.make_graph_loss(History, modelse)\n",
    "        if background:\n",
    "            model.save_weights('model/background/' + str(modelse) + '.h5')\n",
    "        else:\n",
    "            model.save_weights('model/normal/' + str(modelse) + '.h5')\n",
    "        print('le model a été sauvegarder comme étant ' + str(modelse) + '.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}